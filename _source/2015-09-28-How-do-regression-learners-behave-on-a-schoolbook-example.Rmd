---
title: "A deeper insight into random forest regression"
author: jakob
layout: post
---

Let's try out a little toy example to see how all the regression methods integrated in **mlr** behave on a schoolbook example.
Luckily this can be done with just a few lines of code - but let's narrow it done to those which support uncertainty estimation.
<!-- more -->
Let's generate a list with all mlr-learners fitting the criteria.
```{r, message=FALSE}
library(mlr)
learners = listLearners("regr", properties = "se", create = TRUE)
```


Let's generate some easy data:
```{r}
set.seed(123)
n = 50
x = rchisq(n, df = 2, ncp = 3)
y = rnorm(n, mean = (x-2)^2, sd = seq(1, 3, length.out = n)^2)
y[1:5] = -20 # generate some measuring error
toy.task = makeRegrTask(id = "toy", data = data.frame(x,y), target = "y")
```

Now we can already create all the graphs:
```{r regression visualization, messages = FALSE, warning=FALSE, results='hide'}
for(lrn in learners) {
  print(plotLearnerPrediction(lrn, toy.task, cv = 0))
}
```

Hu? It looks like we shamelessly copied the code from the last blog-post.
How easy!
